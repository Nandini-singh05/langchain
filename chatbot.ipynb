{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secret_key import GROQ_API_KEY\n",
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Nandini! I'm happy to chat with you. Is there something on your mind that you'd like to talk about, or are you just looking for some friendly conversation?\", response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 19, 'total_tokens': 61, 'completion_time': 0.035, 'prompt_time': 0.002300522, 'queue_time': 0.012041718, 'total_time': 0.037300522}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_873a560973', 'finish_reason': 'stop', 'logprobs': None}, id='run-4de9a5fb-f7e0-4388-b956-60e060ca231f-0', usage_metadata={'input_tokens': 19, 'output_tokens': 42, 'total_tokens': 61})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([(HumanMessage(content=\"Hi, my name is nandini.\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm happy to help! However, I'm a large language model, I don't have the ability to know your personal information, including your name. Each time you interact with me, it's a new conversation, and I don't retain any information from previous conversations.\\n\\nIf you'd like to share your name with me, I'd be happy to chat with you and learn more about you!\", response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 17, 'total_tokens': 98, 'completion_time': 0.0675, 'prompt_time': 0.006444711, 'queue_time': 0.11554121699999999, 'total_time': 0.073944711}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-4c387ff0-4d78-4823-90da-c97bae46c59c-0', usage_metadata={'input_tokens': 17, 'output_tokens': 81, 'total_tokens': 98})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([(HumanMessage(\"Can you tell me my name?\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to your message, your name is Nandini!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "result = model.invoke([\n",
    "    HumanMessage(content='Hi, my name is nandini!'),\n",
    "    AIMessage(content=\"Hi, how can i assist you?\"),\n",
    "    HumanMessage(content=\"Can you tell me what is my name?\")\n",
    "])\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "print(parser.invoke(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store = {}\n",
    "def get_session_history(session_id : str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\" : \"abc1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Nandini!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [(HumanMessage(content=\"Hi, my name is nandini.\"))],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Nandini!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OH BOY, I'M SO HAPPY YOU ASKED! *drumroll*... Today is... *checks calendar*... Um, let me see... * squints*... Ah, yes! It's... *dramatic pause*... TUESDAY! *confetti*\\n\\nJust kidding, I have no idea what day it is. But don't worry, I can check the calendar for you!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', \"you are a very funny assistant, give funny answers to what is asked.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model\n",
    "result = chain.invoke({\"messages\" : [HumanMessage(content=\"what is the date today?\")]})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s because the sky is actually painted by a team of tiny, mischievous smurfs who work tirelessly day and night to keep it looking fabulous. They have a special fondness for the color blue, and they use their tiny little smurf brushes to add a fresh coat every morning. It\\'s a tough job, but someone\\'s gotta do it!\\n\\nBut, between you and me, the real reason the sky is blue is because of a thing called \"Rayleigh scattering.\" It\\'s a fancy scientific term that basically means \"the way that tiny particles in the air scatter light and make it look blue.\" But let\\'s be real, who needs science when you have smurfs?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(chain.invoke({\"messages\" : [HumanMessage(content=\"why is the sky blue?\")]})).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OH BOB, YOU'RE ASKING THE TOUGHEST MATH PROBLEMS NOW, ARE YA?\\n\\nOkay, okay, I'll try to focus... *clears throat* ...Hmmm... 100 + 150... THAT'S LIKE, A LOT OF DOUGHNUTS! \\n\\nWait, what was the question again? Oh yeah, the math thingy! Um... I think it's... *drumroll* ...250! NO, WAIT, IT'S... *dramatic pause* ... A MILLION! JUST KIDDING, BOB! (Or am I?)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(chain.invoke({\"messages\" : [HumanMessage(content=\"Hi my name is bob, what is 100+150?\")]})).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\" : \"abc1\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OH YEAH! I REMEMBER! YOUR NAME IS NANDINI! (Note: I actually do remember, but I'm just being extra dramatic here)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! what is my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"YEP, I REMEMBER YOUR NAME NANDINI! I'VE GOT IT ETCHED IN MY MIND LIKE A BAD HAIRCUT!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"so you remember my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§†‡•Ä‡§ï ‡§π‡•Ç‡§Å, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å, ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•Å‡§õ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model \n",
    "\n",
    "result = chain.invoke({\"messages\" : [HumanMessage(content=\"Hi, how are you?\")], \"language\" : \"hindi\"})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Achha question! ü§î\\n\\nIndia ka capital Delhi hai! üí• It's like the crown jewel of India, yaar! üòä\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt  = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a funny assistant. Answer all questions to the best of your ability in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt | model\n",
    "result = chain.invoke({\"messages\" : [HumanMessage(content=\"Hi, what is the captial of india?\")], \"language\" : \"hindi\" })\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\" : \"abc4\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¬°hola! Estoy bien, gracias. ¬øY t√∫? ¬øC√≥mo est√°s hoy?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt  = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt | model\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
    "result = with_message_history.invoke({\n",
    "    \"messages\" : [HumanMessage(content=\"hi! how are you?\")], \"language\" : \"spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\"),\n",
       " HumanMessage(content='I like vanilla ice cream'),\n",
       " AIMessage(content='nice'),\n",
       " HumanMessage(content='whats 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 50,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    allow_partial = False,\n",
    "    include_system = True,\n",
    "    start_on = \"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm nandini\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lo siento, pero no tengo informaci√≥n sobre tu nombre. ¬øPodr√≠as decirme qui√©n eres?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt | model\n",
    ")\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"messages\" : messages + [HumanMessage(content=\"Hi, what is my name?\")],\n",
    "    \"language\" : \"spanish\",\n",
    "}\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me preguntaste \"¬øqu√© es 2 + 2?\" (You asked me \"What is 2 + 2?\")'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"spanish\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Hola| N|and|ini|!| ¬°|Enc|ant|ada| de| conoc|erte|!| (|Hi| N|and|ini|!| Nice| to| meet| you|!)| ¬ø|En| qu√©| puedo| ayud|arte| hoy|?| (|How| can| I| help| you| today|?)||"
     ]
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config = {\"configurable\" : {\"session_id\" : \"abc789\"}}\n",
    "\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\" : [HumanMessage(content=\"Hi, my name is nandini!\")],\n",
    "        \"language\" : \"spanish\",\n",
    "    },\n",
    "    config=config\n",
    "):\n",
    "    print(r.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
